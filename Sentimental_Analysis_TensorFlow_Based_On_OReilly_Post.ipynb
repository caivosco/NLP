{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRef. https://github.com/adeshpande3/LSTM-Sentiment-Analysis/blob/master/Oriole%20LSTM.ipynb\\n\\nFirst downloading data and uncompress\\nBe sure all dependecies are for python (libraries)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ref. https://github.com/adeshpande3/LSTM-Sentiment-Analysis/blob/master/Oriole%20LSTM.ipynb\n",
    "\n",
    "First downloading data and uncompress\n",
    "Be sure all dependecies are for python (libraries)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Workflow\\n1 training a word vector generation model like Word2Vec. (or loading\\n                                                 pretrained vectors)\\n2 Creatins and ID matrix for our training set\\n3 RNN with LSTM units and creating and graph for computation\\n4 Training\\n5 Testing\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Workflow\n",
    "1 training a word vector generation model like Word2Vec. (or loading\n",
    "                                                 pretrained vectors)\n",
    "2 Creatins and ID matrix for our training set\n",
    "3 RNN with LSTM units and creating and graph for computation\n",
    "4 Training\n",
    "5 Testing\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use a word2vec trained which will be Glove \n",
    "# it contains 400000 words with 300 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin\r\n",
      "etc\r\n",
      "include\r\n",
      "lib\r\n",
      "lib64\r\n",
      "LSTM-Sentiment-Analysis\r\n",
      "NLP_Exploring.ipynb\r\n",
      "pip-selfcheck.json\r\n",
      "pyvenv.cfg\r\n",
      "Sentimental_Analysis_TensorFlow_Based_On_OReilly_Post.ipynb\r\n",
      "share\r\n"
     ]
    }
   ],
   "source": [
    "# defining/ checking the right directory\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('LSTM-Sentiment-Analysis/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile     models\t\t  positiveReviews\t  wordsList.npy\r\n",
      "idsMatrix.npy  models.tar.gz\t  Pre-Trained LSTM.ipynb  wordVectors.npy\r\n",
      "Images\t       negativeReviews\t  README.md\r\n",
      "LICENSE        Oriole LSTM.ipynb  training_data.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsList = np.load('wordsList.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsList = wordsList.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsList = [word.decode('UTF-8') for word in wordsList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordVectors = np.load('wordVectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wordVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordVectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15272 ,  0.36181 , -0.22168 ,  0.066051,  0.13029 ,  0.37075 ,\n",
       "       -0.75874 , -0.44722 ,  0.22563 ,  0.10208 ,  0.054225,  0.13494 ,\n",
       "       -0.43052 , -0.2134  ,  0.56139 , -0.21445 ,  0.077974,  0.10137 ,\n",
       "       -0.51306 , -0.40295 ,  0.40639 ,  0.23309 ,  0.20696 , -0.12668 ,\n",
       "       -0.50634 , -1.7131  ,  0.077183, -0.39138 , -0.10594 , -0.23743 ,\n",
       "        3.9552  ,  0.66596 , -0.61841 , -0.3268  ,  0.37021 ,  0.25764 ,\n",
       "        0.38977 ,  0.27121 ,  0.043024, -0.34322 ,  0.020339,  0.2142  ,\n",
       "        0.044097,  0.14003 , -0.20079 ,  0.074794, -0.36076 ,  0.43382 ,\n",
       "       -0.084617,  0.1214  ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordVectors[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordVectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9327  ,  1.0421  , -0.78515 ,  0.91033 ,  0.22711 , -0.62158 ,\n",
       "       -1.6493  ,  0.07686 , -0.5868  ,  0.058831,  0.35628 ,  0.68916 ,\n",
       "       -0.50598 ,  0.70473 ,  1.2664  , -0.40031 , -0.020687,  0.80863 ,\n",
       "       -0.90566 , -0.074054, -0.87675 , -0.6291  , -0.12685 ,  0.11524 ,\n",
       "       -0.55685 , -1.6826  , -0.26291 ,  0.22632 ,  0.713   , -1.0828  ,\n",
       "        2.1231  ,  0.49869 ,  0.066711, -0.48226 , -0.17897 ,  0.47699 ,\n",
       "        0.16384 ,  0.16537 , -0.11506 , -0.15962 , -0.94926 , -0.42833 ,\n",
       "       -0.59457 ,  1.3566  , -0.27506 ,  0.19918 , -0.36008 ,  0.55667 ,\n",
       "       -0.70315 ,  0.17157 ], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also search our word list for a word like \"baseball\", \n",
    "# and then access its corresponding vector through \n",
    "# the embedding matrix.\n",
    "baseballIndex = wordsList.index('baseball')\n",
    "wordVectors[baseballIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector representation of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 10 # maximum length of sentence\n",
    "numDimensions = 300 # dimensions for each word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstSentence = np.zeros((maxSeqLength), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstSentence[0] = wordsList.index('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstSentence[1] = wordsList.index('thought')\n",
    "firstSentence[2] = wordsList.index('the')\n",
    "firstSentence[3] = wordsList.index('movie')\n",
    "firstSentence[4] = wordsList.index('was')\n",
    "firstSentence[5] = wordsList.index('incredible')\n",
    "firstSentence[6] = wordsList.index('and')\n",
    "firstSentence[7] = wordsList.index('inspiring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    41,    804, 201534,   1005,     15,   7446,      5,  13767,\n",
       "            0,      0], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors, firstSentence).eval().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess._closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15272 ,  0.36181 , -0.22168 ,  0.066051,  0.13029 ,  0.37075 ,\n",
       "       -0.75874 , -0.44722 ,  0.22563 ,  0.10208 ,  0.054225,  0.13494 ,\n",
       "       -0.43052 , -0.2134  ,  0.56139 , -0.21445 ,  0.077974,  0.10137 ,\n",
       "       -0.51306 , -0.40295 ,  0.40639 ,  0.23309 ,  0.20696 , -0.12668 ,\n",
       "       -0.50634 , -1.7131  ,  0.077183, -0.39138 , -0.10594 , -0.23743 ,\n",
       "        3.9552  ,  0.66596 , -0.61841 , -0.3268  ,  0.37021 ,  0.25764 ,\n",
       "        0.38977 ,  0.27121 ,  0.043024, -0.34322 ,  0.020339,  0.2142  ,\n",
       "        0.044097,  0.14003 , -0.20079 ,  0.074794, -0.36076 ,  0.43382 ,\n",
       "       -0.084617,  0.1214  ], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordVectors[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    41,    804, 201534,   1005,     15,   7446,      5,  13767,\n",
       "            0,      0], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating ids matrix for our imdb review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile     models\t\t  positiveReviews\t  wordsList.npy\r\n",
      "idsMatrix.npy  models.tar.gz\t  Pre-Trained LSTM.ipynb  wordVectors.npy\r\n",
      "Images\t       negativeReviews\t  README.md\r\n",
      "LICENSE        Oriole LSTM.ipynb  training_data.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveFiles = ['positiveReviews/' + f for f in \n",
    "                 listdir('positiveReviews/') if \n",
    "                 isfile(join('positiveReviews/', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeFiles = ['negativeReviews/' + f for f in \n",
    "                 listdir('negativeReviews/') if \n",
    "                 isfile(join('negativeReviews/', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(positiveFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positiveReviews/9257_7.txt'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positiveFiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positiveReviews/4230_10.txt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positiveFiles[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positiveFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### processing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWords = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive files finished\n"
     ]
    }
   ],
   "source": [
    "for pf in positiveFiles:\n",
    "    with open(pf, 'r', encoding='utf-8') as f:\n",
    "        line = f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)\n",
    "print('Positive files finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[148, 177, 71, 337, 105, 410, 188, 250, 158, 275]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numWords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative files finished\n"
     ]
    }
   ],
   "source": [
    "for nf in negativeFiles:\n",
    "    with open(nf, 'r', encoding='utf-8') as f:\n",
    "        line = f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)\n",
    "print('Negative files finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of files is 25000\n",
      "The total number of words in the files is 5844680\n",
      "The average number of words in the files is 233.7872\n"
     ]
    }
   ],
   "source": [
    "numFiles = len(numWords)\n",
    "print('The total number of files is', numFiles)\n",
    "print('The total number of words in the files is', sum(numWords))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using matplotlib to visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFrom the histogram as well as the average number of words \\nper file, we can safely say that most reviews will fall \\nunder 250 words, which is the max sequence length value \\nwe will set.\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "From the histogram as well as the average number of words \n",
    "per file, we can safely say that most reviews will fall \n",
    "under 250 words, which is the max sequence length value \n",
    "we will set.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting to ids matrix only a single file of positiveFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At first glance I expected this film to be crappy because I thought the plot would be so excessively feminist. But I was wrong. As you maybe have read in earlier published comments, I agree in that the feminist part in this film does not bother. I never had the idea that the main character was exaggerating her position as a woman. It's like Guzman is presented as somebody with a spine, this in contrast to her classmates. So I was surprised by the story, in fact, I thought it was quite good, except for the predictable end. Maybe it would've been a better idea to give the plot a radical twist, so that the viewer is somewhat more surprised.<br /><br />In addition, I'd like to say that Rodriguez earned her respect by the way she put away her character. I can't really explain why, but especially in the love scenes she convinced me. It just looked real I think.<br /><br />I gave it a 7 out of 10, merely because of the dull last half hour.\n"
     ]
    }
   ],
   "source": [
    "fname = positiveFiles[1]\n",
    "with open(fname) as f:\n",
    "    for lines in f:\n",
    "        print(lines)\n",
    "        exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At first glance I expected this film to be crappy because I thought the plot would be so excessively feminist. But I was wrong. As you maybe have read in earlier published comments, I agree in that the feminist part in this film does not bother. I never had the idea that the main character was exaggerating her position as a woman. It's like Guzman is presented as somebody with a spine, this in contrast to her classmates. So I was surprised by the story, in fact, I thought it was quite good, except for the predictable end. Maybe it would've been a better idea to give the plot a radical twist, so that the viewer is somewhat more surprised.<br /><br />In addition, I'd like to say that Rodriguez earned her respect by the way she put away her character. I can't really explain why, but especially in the love scenes she convinced me. It just looked real I think.<br /><br />I gave it a 7 out of 10, merely because of the dull last half hour.\n",
      "['At', 'first', 'glance', 'I', 'expected', 'this', 'film', 'to', 'be', 'crappy', 'because', 'I', 'thought', 'the', 'plot', 'would', 'be', 'so', 'excessively', 'feminist.', 'But', 'I', 'was', 'wrong.', 'As', 'you', 'maybe', 'have', 'read', 'in', 'earlier', 'published', 'comments,', 'I', 'agree', 'in', 'that', 'the', 'feminist', 'part', 'in', 'this', 'film', 'does', 'not', 'bother.', 'I', 'never', 'had', 'the', 'idea', 'that', 'the', 'main', 'character', 'was', 'exaggerating', 'her', 'position', 'as', 'a', 'woman.', \"It's\", 'like', 'Guzman', 'is', 'presented', 'as', 'somebody', 'with', 'a', 'spine,', 'this', 'in', 'contrast', 'to', 'her', 'classmates.', 'So', 'I', 'was', 'surprised', 'by', 'the', 'story,', 'in', 'fact,', 'I', 'thought', 'it', 'was', 'quite', 'good,', 'except', 'for', 'the', 'predictable', 'end.', 'Maybe', 'it', \"would've\", 'been', 'a', 'better', 'idea', 'to', 'give', 'the', 'plot', 'a', 'radical', 'twist,', 'so', 'that', 'the', 'viewer', 'is', 'somewhat', 'more', 'surprised.<br', '/><br', '/>In', 'addition,', \"I'd\", 'like', 'to', 'say', 'that', 'Rodriguez', 'earned', 'her', 'respect', 'by', 'the', 'way', 'she', 'put', 'away', 'her', 'character.', 'I', \"can't\", 'really', 'explain', 'why,', 'but', 'especially', 'in', 'the', 'love', 'scenes', 'she', 'convinced', 'me.', 'It', 'just', 'looked', 'real', 'I', 'think.<br', '/><br', '/>I', 'gave', 'it', 'a', '7', 'out', 'of', '10,', 'merely', 'because', 'of', 'the', 'dull', 'last', 'half', 'hour.']\n"
     ]
    }
   ],
   "source": [
    "#how operate readline and split\n",
    "with open(fname) as f:\n",
    "    A1 = f.readline()\n",
    "    print(A1)\n",
    "    A2 = A1.split()\n",
    "    print(A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing to leave only characters\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\",\" \")\n",
    "    return re.sub(strip_special_chars, \" \", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstFile = np.zeros((maxSeqLength), dtype='int32')\n",
    "with open(fname) as f:\n",
    "    indexCounter = 0\n",
    "    line = f.readline()\n",
    "    cleanedLine = cleanSentences(line)\n",
    "    split = cleanedLine.split()\n",
    "    for word in split:\n",
    "        if indexCounter < maxSeqLength:\n",
    "            try:\n",
    "                firstFile[indexCounter] = wordsList.index(word)\n",
    "            except ValueError:\n",
    "                firstFile[indexCounter] = 399999\n",
    "            indexCounter = indexCounter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    22,     58,  10145,     41,    287,     37,    319,      4,\n",
       "           30, 100580,    113,     41,    804, 201534,   2219,     54,\n",
       "           30,    100,  23808, 399999,     34,     41,     15, 399999,\n",
       "           19,     81,   1881,     33,   1465,      6,    350,    735,\n",
       "       399999,     41,   2137,      6,     12, 201534,  11853,    153,\n",
       "            6,     37,    319,    260,     36, 399999,     41,    332,\n",
       "           40, 201534,   1159,     12, 201534,    444,   1395,     15,\n",
       "        30459,     71,    704,     19,      7, 399999, 399999,    117,\n",
       "        17301,     14,   1923,     19,   4377,     17,      7, 399999,\n",
       "           37,      6,   3313,      4,     71, 399999,    100,     41,\n",
       "           15,   3553,     21, 201534, 399999,      6, 399999,     41,\n",
       "          804,     20,     15,   1689, 399999,   2077,     10, 201534,\n",
       "        12670, 399999,   1881,     20, 399999,     51,      7,    439,\n",
       "         1159,      4,    455, 201534,   2219,      7,   3412, 399999,\n",
       "          100,     12, 201534,  12514,     14,   3779,     56, 399999,\n",
       "            6, 399999, 399999,    117,      4,    203,     12,   4461,\n",
       "         1770,     71,   1983,     21, 201534,    179,     67,    339,\n",
       "          420,     71, 399999,     41, 399999,    588,   3392, 399999,\n",
       "           34,    858,      6, 201534,    835,   3468,     67,   3958,\n",
       "       149208,     20,    120,   1803,    567,     41, 399999,     41,\n",
       "          646,     20,      7,    632,     66,      3, 399999,   4544,\n",
       "          113,      3, 201534,  13271,     76,    343, 399999,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0], dtype=int32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(firstFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because is so expensive compute 250000 reviews to get\n",
    "# a ids matrix\n",
    "# well, we load a pre-computed matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile     models\t\t  positiveReviews\t  wordsList.npy\r\n",
      "idsMatrix.npy  models.tar.gz\t  Pre-Trained LSTM.ipynb  wordVectors.npy\r\n",
      "Images\t       negativeReviews\t  README.md\r\n",
      "LICENSE        Oriole LSTM.ipynb  training_data.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.load('idsMatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 250)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions that you will find helping when training the network later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        if (i % 2 == 0):\n",
    "            num = randint(1, 11499)\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            num = randint(13499, 24999)\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(11499,13499)\n",
    "        if (num <= 12999):\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.placeholder is used to feed actual training examples\n",
    "\n",
    "# tf.Variable for is used for trainable variables \n",
    "# such as weights (W) and biases (B) for your model.\n",
    "\n",
    "# CONCLUSION: \n",
    "# Variables are trained over time, \n",
    "# Placeholders are input data that doesn't change \n",
    "# as your model trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining some parameter \n",
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting our word vector\n",
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]), dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LSTM cell\n",
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting first output of a rnn\n",
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct prediction and accuracy metrics \n",
    "# to track how the network is doing\n",
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-78-731620551d72>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining a standard cross entropy loss with a softmax layer\n",
    "# For the optimizer, we’ll use Adam \n",
    "# default learning rate of .001\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\n",
    "                     (logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-79-c607849da4b6>:1: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(24, 250, 300) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/basic_lstm_cell/kernel:0' shape=(114, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/basic_lstm_cell/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(64, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/basic_lstm_cell/kernel/Adam:0' shape=(114, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/basic_lstm_cell/kernel/Adam_1:0' shape=(114, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/basic_lstm_cell/bias/Adam:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/basic_lstm_cell/bias/Adam_1:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1/Adam:0' shape=(64, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1/Adam_1:0' shape=(64, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2/Adam:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2/Adam_1:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-06-22 16:09:35--  https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/contrib/rnn/python/tools/checkpoint_convert.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.4.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.4.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11728 (11K) [text/plain]\n",
      "Saving to: ‘checkpoint_convert.py’\n",
      "\n",
      "checkpoint_convert. 100%[===================>]  11,45K  --.-KB/s    in 0,04s   \n",
      "\n",
      "2018-06-22 16:09:36 (276 KB/s) - ‘checkpoint_convert.py’ saved [11728/11728]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/contrib/rnn/python/tools/checkpoint_convert.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_convert.py  models\t\t  Pre-Trained LSTM.ipynb\r\n",
      "Dockerfile\t       models.tar.gz\t  README.md\r\n",
      "idsMatrix.npy\t       negativeReviews\t  training_data.tar.gz\r\n",
      "Images\t\t       Oriole LSTM.ipynb  wordsList.npy\r\n",
      "LICENSE\t\t       positiveReviews\t  wordVectors.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-22 16:09:38.197202: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n"
     ]
    }
   ],
   "source": [
    "!python checkpoint_convert.py models/pretrained_lstm.ckpt-90000 converted-checkpoints/pretrained_lstm-90000.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 297580\r\n",
      "drwxrwxr-x 8 ivan ivan     4096 jun 22 16:09 .\r\n",
      "drwxrwxr-x 9 ivan ivan     4096 jun 22 15:54 ..\r\n",
      "-rw-rw-r-- 1 ivan ivan    11728 jun 22 16:09 checkpoint_convert.py\r\n",
      "drwxr-xr-x 2 ivan ivan     4096 jun 22 16:09 converted-checkpoints\r\n",
      "-rw-rw-r-- 1 ivan ivan      378 jun 21 15:34 Dockerfile\r\n",
      "drwxrwxr-x 8 ivan ivan     4096 jun 21 15:34 .git\r\n",
      "-rw-rw-r-- 1 ivan ivan       10 jun 21 15:34 .gitignore\r\n",
      "-rw-r--r-- 1 ivan ivan 25000080 mar 13  2017 idsMatrix.npy\r\n",
      "drwxrwxr-x 2 ivan ivan     4096 jun 21 15:34 Images\r\n",
      "-rw-rw-r-- 1 ivan ivan     1071 jun 21 15:34 LICENSE\r\n",
      "drwxrwxr-x 2 ivan ivan     4096 mar 27  2017 models\r\n",
      "-rw-rw-r-- 1 ivan ivan 73618696 jun 21 15:34 models.tar.gz\r\n",
      "drwxr-xr-x 2 ivan ivan   344064 awr 12  2011 negativeReviews\r\n",
      "-rw-rw-r-- 1 ivan ivan    44643 jun 21 15:34 Oriole LSTM.ipynb\r\n",
      "drwxr-xr-x 2 ivan ivan   348160 awr 12  2011 positiveReviews\r\n",
      "-rw-rw-r-- 1 ivan ivan     6976 jun 21 15:34 Pre-Trained LSTM.ipynb\r\n",
      "-rw-rw-r-- 1 ivan ivan     4242 jun 21 15:34 README.md\r\n",
      "-rw-rw-r-- 1 ivan ivan 98090940 jun 21 15:34 training_data.tar.gz\r\n",
      "-rw-r--r-- 1 ivan ivan 27200080 mar 13  2017 wordsList.npy\r\n",
      "-rw-r--r-- 1 ivan ivan 80000080 mar 23  2017 wordVectors.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls -all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv converted-checkpoints models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 297576\r\n",
      "drwxrwxr-x 7 ivan ivan     4096 jun 22 16:09 .\r\n",
      "drwxrwxr-x 9 ivan ivan     4096 jun 22 15:54 ..\r\n",
      "-rw-rw-r-- 1 ivan ivan    11728 jun 22 16:09 checkpoint_convert.py\r\n",
      "-rw-rw-r-- 1 ivan ivan      378 jun 21 15:34 Dockerfile\r\n",
      "drwxrwxr-x 8 ivan ivan     4096 jun 21 15:34 .git\r\n",
      "-rw-rw-r-- 1 ivan ivan       10 jun 21 15:34 .gitignore\r\n",
      "-rw-r--r-- 1 ivan ivan 25000080 mar 13  2017 idsMatrix.npy\r\n",
      "drwxrwxr-x 2 ivan ivan     4096 jun 21 15:34 Images\r\n",
      "-rw-rw-r-- 1 ivan ivan     1071 jun 21 15:34 LICENSE\r\n",
      "drwxr-xr-x 2 ivan ivan     4096 jun 22 16:09 models\r\n",
      "-rw-rw-r-- 1 ivan ivan 73618696 jun 21 15:34 models.tar.gz\r\n",
      "drwxr-xr-x 2 ivan ivan   344064 awr 12  2011 negativeReviews\r\n",
      "-rw-rw-r-- 1 ivan ivan    44643 jun 21 15:34 Oriole LSTM.ipynb\r\n",
      "drwxr-xr-x 2 ivan ivan   348160 awr 12  2011 positiveReviews\r\n",
      "-rw-rw-r-- 1 ivan ivan     6976 jun 21 15:34 Pre-Trained LSTM.ipynb\r\n",
      "-rw-rw-r-- 1 ivan ivan     4242 jun 21 15:34 README.md\r\n",
      "-rw-rw-r-- 1 ivan ivan 98090940 jun 21 15:34 training_data.tar.gz\r\n",
      "-rw-r--r-- 1 ivan ivan 27200080 mar 13  2017 wordsList.npy\r\n",
      "-rw-r--r-- 1 ivan ivan 80000080 mar 23  2017 wordVectors.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls -all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/pretrained_lstm-90000.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 66.66666865348816\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 58.33333134651184\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 70.83333134651184\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 58.33333134651184\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\r\n",
      "pretrained_lstm-90000.ckpt.data-00000-of-00001\r\n",
      "pretrained_lstm-90000.ckpt.index\r\n",
      "pretrained_lstm-90000.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
